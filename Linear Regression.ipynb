{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression falls under the category of supervised learning, meaning that in order to create our model we need to use a training set. Linear regression is an inflexible model. Linear regression can only those model those data sets that follow a linear pattern. Inflexiblity improves the ability to infere, or understand those predictors that contribute more or less to the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we assume that there exists a linear relationship between X and Y. We will describe this relationship as being approximate, and hence we use \"$\\approx$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Y \\approx \\beta_{0} + \\beta_{1}X $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in any linear relationship, in this model $\\beta_{0}$ represents the Y intercept and $\\beta_{1}$ is the slope of the line. We do not know know what the coefficients ($\\beta_{0}$ and $\\beta_{1}$) are, so we have to estimate them using the training set. We will refer to the estimated coefficients as $\\hat{\\beta}_{0}$ and $\\hat{\\beta}_{1}$ and the predicted response $\\hat{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} \\approx \\hat{\\beta}_{0} + \\hat{\\beta}_{1}X$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating $\\hat{\\beta}_{0}$ and $\\hat{\\beta}_{1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is used to determine the coefficients. The n observation points of the training set will be represented by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(x_{1},y_{1}), (x_{2},y_{2}), ..., (x_{n},y_{n})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to find the closet match of the estimated coefficients to the coefficients that represent the actual linear function. The most widely used approach is that of the least squares, though there are a number of others. Using the equation $\\hat{y}_{i} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}x_{i}$ to predict Y, we are left with the error e, which is the difference between the observed response value $y_{i}$ and the prediction value $\\hat{y}_{i}$. This difference is called the residual. To use the least squares method, we need to add up all of the residuals in the training set. This is called the Residual Sum of Squares (RSS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$RSS=\\hat{e}_{1}^2+\\hat{e}_{2}^2+...+\\hat{e}_{n}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also written as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$RSS=(y_{1}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{1})^2 + (y_{2}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{2})^2+...+(y_{n}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1}x_{n})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the RSS equation we can solve for $\\hat{\\beta}_{0}$ and $\\hat{\\beta}_{1}$. Khan academy has a few videos that goes over the proofs for arriving at the formulas. These videos can be found starting here: https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/more-on-regression/v/squared-error-of-regression-line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\beta}_{1}=\\sum_{i=1}^n \\frac{(x_{i}-\\bar{x})(y_{i}-\\bar{y})}{\\sum_{i=1}^n(x_{i}-\\bar{x})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\beta}_{0}=\\bar{y}-\\hat{\\beta}_{1}\\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $\\bar{y}$ and $\\bar{x}$ are the sample means. The two equations above are significant in that they represent the minimized values of the RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use y=.5x+4 as our linear equation which of course is supposed to be the unknown function we are trying to figure out. We first will create a plot of what the function looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4VHXe/vH3NxAIJQRCDSWEEggBAkIoggUFFRRFwLoW\nVFbcdfuzKwlgxwKWXf25NnTtro2AICoqKPYCqCQhJBBCJyQQIAkJqfN9/sj8novHB5YAMzkzZ+7X\ndXFl5szMNffXkJvjmXM+MdZaREQk+IU5HUBERHxDhS4i4hIqdBERl1Chi4i4hApdRMQlVOgiIi6h\nQhcRcQkVuoiIS6jQRURconFDvlm7du1sXFxcQ76liEjQW7t27T5rbfvjPa9BCz0uLo41a9Y05FuK\niAQ9Y8y2+jxPh1xERFxChS4i4hIqdBERl1Chi4i4hApdRMQlVOgiIi6hQhcRcQkVuoiIHx0oq+Ke\n99ZTUlHt9/dq0AuLRERChbWWDzL2cNfSTA6WVzO6VzvGJXb063uq0EVEfKywpII7lmTy0foCBnaJ\n4tXpI+gX08rv76tCFxHxEWst76zZydz3s6iq8TBrQgLTz+hB40YNc3RbhS4i4gPbi8qZvTiDr3L3\nMbxHNPOnJtGjXYsGzaBCFxE5BbUey0vfbOWRj3JoFGa479IB/Gp4LGFhpsGzqNBFRE7SpoJSZqal\n89P2g5zTtz33Tx5I59bNHMujQhcROUFVNR6e+XwzT3y6iZZNG/PYlYOZNLgzxjT8XvmRVOgiIidg\n3Y6DpKSlk72nlIsHdebuixNp27Kp07EAFbqISL0crqrlsRUbee7LPNpHNuW565M5z8/nlZ8oFbqI\nyHF8l1dEalo6W4vKuXp4LLMuTKBVRLjTsf4PFbqIyDGUVlQz78NsXv9+O93bNuffN49gVK92Tsc6\npnoVujFmK1AK1AI11tpkY0w08BYQB2wFrrDWHvBPTBGRhvVpdgFzFmdSUFLBzWf24L/O60uzJo2c\njvUfncge+jnW2n1H3E8FVlpr5xljUr33U3yaTkSkgRUdquTeZVks+Xk3fTtG8vS1QxncrbXTserl\nVA65TALGeG+/DKxChS4iQcpay7L0fO5eWjcZ8c/j4rl1TG+aNA6eobT1LXQLrDDG1ALPWmsXAB2t\ntfnex/cAR/241xgzA5gBEBsbe4pxRUR8b09xBbe/m8GKDYUM6taah6Ym0bdTpNOxTlh9C/0Ma+0u\nY0wH4BNjTPaRD1prrTHGHu2F3vJfAJCcnHzU54iIOMFay5urd/DA+xuo9ni4/aJ+3Di6B40cuGzf\nF+pV6NbaXd6vhcaYxcBwoMAYE2OtzTfGxACFfswpIuJT24rKSE3L4Nu8Ik7v2ZZ5UwfSvW3DDtPy\nteMWujGmBRBmrS313j4fuBdYCkwD5nm/LvFnUBERX6j1WF74aguPfpJDeFgYD04ZyFXDujl+2b4v\n1GcPvSOw2LvYxsC/rbXLjTGrgbeNMdOBbcAV/ospInLqcvaUMnPhOtbtLGZcv47cd+kAOkVFOB3L\nZ45b6NbaPGDQUbYXAWP9EUpExJeqajw8+VkuT63KpVVEOE9cfRoTk2JcsVd+JF0pKiKu9tP2A6Sk\npbOx4BCTT+vCHRMTiW7RxOlYfqFCFxFXKq+q4dGPN/LC11vo1CqCF25I5tyEwBqm5WsqdBFxnW9y\n95G6KIPt+8u5ZkQsqRMSiAzAYVq+pkIXEdcoPlzNgx9s4M3VO4hr25w3Z4xkZM+2TsdqMCp0EXGF\nT7IKuP3dDPaWVnLL2T35y7g+RIQH9jAtX1Ohi0hQ23eokruXrmdZej4JnSJ57vpkkroGxzAtX1Oh\ni0hQstay5Ofd3PPeesoqa/nreX245exeQTVMy9dU6CISdHYfPMzt72byaXYhp8XWDdOK7xh8w7R8\nTYUuIkHD47H8+4ftzPswm1qP5c6JiUwbFRe0w7R8TYUuIkFhy74yUtLS+WHLfkb3bsuDk5OIbdvc\n6VgBRYUuIgGtptbD819t4R+fbKRp4zAemprE5cldXXfZvi+o0EUkYGXtLiElLZ2MXcWcn9iRuZcO\noGMr9wzT8jUVuogEnMqaWv75aS5Pr9pM6+bhPHXNECYM6KS98uNQoYtIQFm7rW6YVm7hIaYM6cId\nFyXSxqXDtHxNhS4iAaGssoZHPs7hpW+20jmqGS/dOIwxfTs4HSuoqNBFxHFfbtrLrEUZ7DxwmOtP\n787M8Qm0bKp6OlH6LyYijikur+b+D7J4e81OerZrwdu3nM7wHtFOxwpaKnQRccTyzD3csSST/WVV\n/HZML/40Nj7khmn5mgpdRBrU3tK6YVrvZ+STGNOKF28YxoAuUU7HcgUVuog0CGsti37cxb3Lsjhc\nVcttF/Rlxlk9CW8UusO0fE2FLiJ+t/NAObMXZ/LFxr0M7d6G+VOT6N2hpdOxXEeFLiJ+4/FYXvt+\nG/M/zMYC91zSn+tGdidMw7T8QoUuIn6xee8hUtPSWb31AGfGt+OByQPpFq1hWv6kQhcRn6qu9fDc\nl3k8tmITzcIb8cjlg5g6pIsu228AKnQR8ZnMXcWkpKWzfncJ4/t34t5L+9MhUsO0GooKXUROWUV1\nLU98uolnPs+jTfMmPH3NECYMjHE6VshRoYvIKVmzdT8z09LJ21vG1CFduWNiP1o31zAtJ6jQReSk\nlFXW8NDybF75bhudo5rxyk3DOatPe6djhTQVuoicsM837mX2ogx2Fx9m2ulx3HZBX1pomJbj9B0Q\nkXo7WF7F3GUbSPtxJ73at+CdW04nOU7DtAJFvQvdGNMIWAPsstZONMZEA28BccBW4Apr7QF/hBQR\n532Qkc+dSzI5WF7N787pxR/O1TCtQHMiQxT+BGw44n4qsNJaGw+s9N4XEZcpLKngN6+u5dbXf6RT\nVARLfj+a2y5IUJkHoHrtoRtjugIXAfcD/+XdPAkY4739MrAKSPFtPBFxirWWd9bu5L5lWVTUeEgZ\nn8DNZ/agsYZpBaz6HnJ5DJgJRB6xraO1Nt97ew/Q0ZfBRMQ5O/aXM3txBl9u2sfwuGjmTR1Iz/Ya\nphXojlvoxpiJQKG1dq0xZszRnmOttcYYe4zXzwBmAMTGxp5CVBHxt1qP5ZVvt/LwRzkYYO6k/lwz\nQsO0gkV99tBHA5cYYy4EIoBWxpjXgAJjTIy1Nt8YEwMUHu3F1toFwAKA5OTko5a+iDgvt7CUlLQM\n1m47wNl92vPAlIF0ad3M6VhyAo57MMxaO8ta29VaGwdcBXxqrb0WWApM8z5tGrDEbylFxG+qaz38\n89NNXPj4V2zee4i/XzGIl24cpjIPQqdyHvo84G1jzHRgG3CFbyKJSEPJ3FXMbQvT2ZBfwkVJMdx9\ncX/aRzZ1OpacpBMqdGvtKurOZsFaWwSM9X0kEfG3iupaHluxiee+zCO6RROevW4oF/Tv5HQsOUW6\nUlQkxHyfV0Tqogy27CvjyuRuzL6wH1HNw52OJT6gQhcJEaUV1cxfns1r322na5tmvDZ9BGfEt3M6\nlviQCl0kBHyWU8icRRnkl1Qw/Ywe/PX8PjRvoh9/t9F3VMTF9pdVMXdZFot/2kV8h5ak/XYUQ2Lb\nOB1L/ESFLuJC1lrez8jnriXrKT5czR/HxvO7c3rRtLHmr7iZCl3EZQpKKrj93Uw+ySpgYJcoXvv1\nCPrFtHI6ljQAFbqIS1hreXvNDu57fwNVNR5mX5jATaM1TCuUqNBFXGB7UTmpi9L5ZnMRI3pEM39q\nEnHtWjgdSxqYCl0kiNV6LC9+vYVHPs6hcVgY908ewNXDYjVMK0Sp0EWC1MaCUmYuTOfnHQc5N6ED\n908eQEyU5q+EMhW6SJCpqvHwzOebeeLTTURGhPP4VYO5ZFBnjNFeeahToYsEkXU7DpKSlk72nlIu\nHtSZuy9OpG1LDdOSOip0kSBwuKqWf6zYyPNf5tEhMoLnr09mXKJ+SZj8byp0kQD3XV4RqWnpbC0q\n51cjYkmdkECrCA3Tkv9LhS4SoEorqpn3YTavf7+d7m2b8++bRzCql4ZpybGp0EUC0MoNBcxZnElh\naQUzzurJX8b1oVkTXbYv/5kKXSSAFB2q5J73sli6bjd9O0byzHVDGdyttdOxJEio0EUCgLWWpet2\nc897WZRWVPPncfHcOqY3TRrrsn2pPxW6iMPyiw9z++JMVmYXMrhbax66LIk+HSOdjiVBSIUu4hCP\nx/LG6u08+EE2NR4Pt1/UjxtH96CRLtuXk6RCF3HA1n1lpC5K57u8/Yzq1ZZ5U5KIbdvc6VgS5FTo\nIg2optbDC19v4dGPN9KkURjzpgzkymHddNm++IQKXaSBZO8pIWVhOut2FjOuX0fuu3QAnaIinI4l\nLqJCF/GzyppanvxsM099lktUs3CeuPo0JibFaK9cfE6FLuJHP20/QEpaOhsLDjH5tC7cMTGR6BZN\nnI4lLqVCF/GD8qoaHv14Iy98vYVOrSJ44YZkzk3QMC3xLxW6iI99k7uP1EUZbN9fzrUjY0kZn0Ck\nhmlJA1Chi/hI8eFqHvxgA2+u3kFc2+a8OWMkI3u2dTqWhBAVuogPfJJVwO3vZrC3tJJbzq4bphUR\nrmFa0rBU6CKnYN+hSu5eup5l6fkkdIrkueuTSeqqYVriDBW6yEmw1rLk593c8956yipr+et5ffjN\nmF6EN9IwLXHOcQvdGBMBfAE09T5/obX2LmNMNPAWEAdsBa6w1h7wX1SRwLD74GHmLM7gs5y9nBbb\nmoemJhGvYVoSAOqzh14JnGutPWSMCQe+MsZ8CEwBVlpr5xljUoFUIMWPWUUc5fFYXv9hO/M/zKbW\nY7lzYiLTRsVpmJYEjOMWurXWAoe8d8O9fywwCRjj3f4ysAoVurjUln1lpKSl88OW/ZzRux0PThlI\nt2gN05LAUq9j6MaYRsBaoDfwpLX2e2NMR2ttvvcpewBdNSGuU1Pr4V9fbeHvn2ykSeMwHpqaxOXJ\nXXXZvgSkehW6tbYWGGyMaQ0sNsYM+MXj1hhjj/ZaY8wMYAZAbGzsKcYVaThZu0tISUsnY1cx5yd2\nZO6lA+jYSsO0JHCd0Fku1tqDxpjPgPFAgTEmxlqbb4yJAQqP8ZoFwAKA5OTko5a+SCCprKnln5/m\n8vSqzbRuHs5T1wxhwoBO2iuXgFefs1zaA9XeMm8GnAfMB5YC04B53q9L/BlUpCGs3VY3TCu38BBT\nvMO02miYlgSJ+uyhxwAve4+jhwFvW2uXGWO+Bd42xkwHtgFX+DGniF+VVdbwyMc5vPTNVjpHNeOl\nG4cxpm8Hp2OJnJD6nOWSDpx2lO1FwFh/hBJpSF9u2susRRnsPHCYaad357bxCbRsqmvuJPjob62E\nrOLyau7/IIu31+ykZ/sWvPOb0xkWF+10LJGTpkKXkLQ8M587lqxnf1kVt47pxR/HxmuYlgQ9FbqE\nlMLSCu5asp4PM/eQGNOKF28YxoAuUU7HEvEJFbqEBGstaT/uYu6yLA5X13LbBX2ZcVZPDdMSV1Gh\ni+vtPFDO7MWZfLFxL8nd2zBvahK9O7R0OpaIz6nQxbU8Hssr327loY9yALjnkv5cN7I7YRqmJS6l\nQhdXyi08RGpaOmu2HeDM+LphWl3baJiWuJsKXVylutbDgi/yeHzFJiLCw3j4siQuG6phWhIaVOji\nGpm7ipm5MJ2s/BIuHNiJuy/pT4dIDdOS0KFCl6BXUV3L4ys3seCLPKJbNOGZa4cwfkCM07FEGpwK\nXYLa6q37SUlLJ29vGZcP7crtFyUS1Tzc6VgijlChS1A6VFnDQ8uzeeXbbXRp3YxXpw/nzPj2TscS\ncZQKXYLO5xv3MntRBruLD3Pj6Dj+dn5fWmiYlogKXYLHwfIq5i7bQNqPO+ndoSULfzOKod3bOB1L\nJGCo0CXgWWv5MHMPdy7J5GB5Nb8/pzd/GNubpo01TEvkSCp0CWiFJRXcsSSTj9YXMKBLK165aQSJ\nnVs5HUskIKnQJSBZa3ln7U7uW5ZFZY2HWRMSmH5GDxprmJbIManQJeDs2F/OrEUZfJW7j+E9opk3\nZSA922uYlsjxqNAlYNT+/2Fay3MIM3DfpQP41fBYDdMSqScVugSE3MJSZi5M58ftBxnTtz0PTB5I\n59bNnI4lElRU6OKo6loPz36+mf+3MpcWTRvx2JWDmTS4s4ZpiZwEFbo4JmNnMbctXEf2nlIuSorh\nnkv6065lU6djiQQtFbo0uIrqWh5bsYnnvsyjbYsmPHvdUC7o38npWCJBT4UuDer7vCJSF2WwZV8Z\nVw3rxqwL+xHVTMO0RHxBhS4NorSimvnLs3ntu+10i27G678eweje7ZyOJeIqKnTxu8+yC5mzOIP8\nkgpuGt2Dv13Qh+ZN9FdPxNf0UyV+s7+sirnLslj80y7iO7Qk7bejGBKrYVoi/qJCF5+z1rIsPZ+7\nl66n+HA1fxobz63n9NIwLRE/U6GLTxWUVDBncSYrNhSQ1DWK128eQUInDdMSaQgqdPEJay1vrd7B\n/R9soKrGw+wLE7hptIZpiTQkFbqcsm1FZcxalME3m4sY2TOaeVOSiGvXwulYIiHnuIVujOkGvAJ0\nBCywwFr7uDEmGngLiAO2AldYaw/4L6oEmlqP5cWvt/DIxzmEh4XxwOSBXDWsm4ZpiTikPnvoNcBf\nrbU/GmMigbXGmE+AG4CV1tp5xphUIBVI8V9UCSQ5e0pJSUvn5x0HGZvQgfsmDyAmSsO0RJx03EK3\n1uYD+d7bpcaYDUAXYBIwxvu0l4FVqNBdr6rGw1Orcnnys1wiI8J5/KrBXDJIw7REAsEJHUM3xsQB\npwHfAx29ZQ+wh7pDMuJi63YcZObCdHIKSrlkUGfuujiRthqmJRIw6l3oxpiWQBrwZ2ttyZF7ZNZa\na4yxx3jdDGAGQGxs7KmlFUccrqrl75/k8K+vttA+sinPX5/MuET9+y0SaOpV6MaYcOrK/HVr7SLv\n5gJjTIy1Nt8YEwMUHu211toFwAKA5OTko5a+BK5vNxeRuiidbUXl/GpELKkTEmgVoWFaIoGoPme5\nGOBfwAZr7d+PeGgpMA2Y5/26xC8JxRElFdU8+EE2b/ywne5tm/Pvm0cwqpeGaYkEsvrsoY8GrgMy\njDE/e7fNpq7I3zbGTAe2AVf4J6I0tJUbCpizOJPC0gpmnNWTv4zrQ7MmumxfJNDV5yyXr4BjncIw\n1rdxxElFhyq5570slq7bTUKnSJ69biiDurV2OpaI1JOuFBWstSxdt5t73suitKKav4zrw2/H9KJJ\nY122LxJMVOghLr/4MLcvzmRldiGDurXm4cuS6NMx0ulYInISVOghyuOxvLF6Ow9+kE2tx3LHxERu\nGBVHI122LxK0VOghaOu+MlIXpfNd3n5G927Lg5OTiG3b3OlYInKKVOghpKbWwwtfb+HRjzfSpHEY\n86cO5IrkbrpsX8QlVOghIntPCSkL01m3s5hx/Tpy/+QBdGwV4XQsEfEhFbrLVdbU8tRnm3lqVS6t\nIsJ54urTmJgUo71yERdSobvYT9sPkJKWzsaCQ1w6uDN3Xtyf6BZNnI4lIn6iQneh8qoaHv14Iy98\nvYVOrSJ48YZhnJPQwelYIuJnKnSX+SZ3H6mLMti+v5xrR8aSMj6BSA3TEgkJKnSXKD5czYMfbODN\n1TuIa9uct2aMZETPtk7HEpEGpEJ3gY/X7+H2dzPZd6iSW86uG6YVEa5hWiKhRoUexPaWVnL3e+t5\nPz2fhE6RPD8tmaSuGqYlEqpU6EHIWsvin3Zx77Isyitr+dv5fbjl7F6EN9IwLZFQpkIPMrsOHmbO\n4gxW5exlSGxr5k9NIl7DtEQEFXrQ8Hgsr3+/jXkfZuOxcOfERKZpmJaIHEGFHgTy9h4iNS2DH7bu\n58z4djwweSDdojVMS0T+NxV6AKup9bDgyzweW7GJiMZhPHRZEpcP7arL9kXkqFToAWr97mJS0tLJ\n3FXC+P6duPfS/nSI1DAtETk2FXqAqaiu5Z+f5vLM55tp3bwJT18zhAkDY5yOJSJBQIUeQNZu28/M\nhels3lvGlCFduHNiIq2ba5iWiNSPCj0AlFXW8PBHObz87VY6RzXjpRuHMaavhmmJyIlRoTvsy017\nmbUog10HD3P9yO7cNj6Blk31bRGRE6fmcEhxeTVz389i4dqd9GzfgrdvOZ1hcdFOxxKRIKZCd8Dy\nzHzuWLKe/WVV3DqmF38cG69hWiJyylToDaiwtIK7lqznw8w99O/cihdvGMaALlFOxxIRl1ChNwBr\nLWk/7mLusiwOV9dy2wV9mXFWTw3TEhGfUqH72Y795cxenMGXm/aR3L0N8y9Lolf7lk7HEhEXUqH7\nicdjefW7bcxfno0B7p3Un2tHdCdMw7RExE9U6H6QW3iI1LR01mw7wFl92vPA5AF0baNhWiLiXyp0\nH6qu9bDgizweX7GJZk0a8ejlg5gypIuGaYlIgzhuoRtjXgAmAoXW2gHebdHAW0AcsBW4wlp7wH8x\nA1/mrmJmLkwnK7+ECwd24u5LNExLRBpWfU6zeAkY/4ttqcBKa208sNJ7PyRVVNfy0PJsJj35NXsP\nVfLMtUN56pqhKnMRaXDH3UO31n5hjIn7xeZJwBjv7ZeBVUCKD3MFhdVb95OyMJ28fWVcPrQrt1+U\nSFTzcKdjiUiIOtlj6B2ttfne23uAjj7KExQOVdbw8PJsXvluG11aN+PV6cM5M76907FEJMSd8oei\n1lprjLHHetwYMwOYARAbG3uqb+e4VTmFzFmcye7iw9wwKo6/nd+XFhqmJSIB4GSbqMAYE2OtzTfG\nxACFx3qitXYBsAAgOTn5mMUf6A6UVTH3/SwW/biL3h1asvA3oxjavY3TsURE/sfJFvpSYBowz/t1\nic8SBRhrLR9m7uHOJZkcLK/m9+f05g9je9O0sYZpiUhgqc9pi29Q9wFoO2PMTuAu6or8bWPMdGAb\ncIU/QzqlsKSCO5Zk8tH6AgZ2ieKVm0aQ2LmV07FERI6qPme5XH2Mh8b6OEvAsNbyzpqd3Pd+FpU1\nHlInJPDrM3rQWMO0RCSA6dO8X9ixv5xZizL4Kncfw3tEM2/KQHpqmJaIBAEVuletx/LyN1t5+KMc\nGoUZ7rt0AL8aHqthWiISNFTowKaCUlLS0vlx+0HO6due+ycPpHPrZk7HEhE5ISFd6FU1Hp79fDNP\nfJpLi6aNeOzKwUwa3FnDtEQkKIVsoafvPMjMhelk7ynl4kGdueviRNq1bOp0LBGRkxZyhV5RXcs/\nPtnIc1/m0a5lU567PpnzEkNqcoGIuFRIFfp3eUWkpqWztaicK5O7MfuifkQ10zAtEXGHkCj00opq\n5n2Yzevfb6dbdDNe//UIRvdu53QsERGfcn2hf5ZdyOzFGRSUVPDrM3rwX+f3oXkT1y9bREKQa5tt\nf1kV9763nnd/3k18h5Y89dtRnBarYVoi4l6uK3RrLcvS87l76XpKKqr509h4bj2nl4ZpiYjruarQ\nC0oqmLM4kxUbChjUNYr5l40goZOGaYlIaHBFoVtreWv1Du7/YAPVtR7mXNiPm87oQSNdti8iISTo\nC31bURmpaRl8m1fEyJ7RzJuSRFy7Fk7HEhFpcEFb6LUey4tfb+GRj3MIDwvjgckDuWpYNw3TEpGQ\nFZSFnrOnlJlp6azbcZCxCR24b/IAYqI0TEtEQltQFXpVjYenVuXy5Ge5REaE8/hVg7lkkIZpiYhA\nEBX6zzsOkrIwnZyCUi7xDtNqq2FaIiL/IygK/YmVm/jHio10iIzgX9OSGdtPw7RERH4pKAo9tm1z\nrhoeS+qEBFpFaJiWiMjRBEWhTxrchUmDuzgdQ0QkoOnX2IuIuIQKXUTEJVToIiIuoUIXEXEJFbqI\niEuo0EVEXEKFLiLiEip0ERGXMNbahnszY/YC207y5e2AfT6MEyxCcd2huGYIzXWH4prhxNfd3Vrb\n/nhPatBCPxXGmDXW2mSnczS0UFx3KK4ZQnPdobhm8N+6dchFRMQlVOgiIi4RTIW+wOkADgnFdYfi\nmiE01x2KawY/rTtojqGLiMh/Fkx76CIi8h8ERaEbY8YbY3KMMbnGmFSn8/iDMaabMeYzY0yWMWa9\nMeZP3u3RxphPjDGbvF/bOJ3V14wxjYwxPxljlnnvh8KaWxtjFhpjso0xG4wxp7t93caYv3j/bmca\nY94wxkS4cc3GmBeMMYXGmMwjth1zncaYWd5uyzHGXHAq7x3whW6MaQQ8CUwAEoGrjTGJzqbyixrg\nr9baRGAk8DvvOlOBldbaeGCl977b/AnYcMT9UFjz48Bya20CMIi69bt23caYLsAfgWRr7QCgEXAV\n7lzzS8D4X2w76jq9P+NXAf29r3nK23knJeALHRgO5Fpr86y1VcCbwCSHM/mctTbfWvuj93YpdT/g\nXahb68vep70MXOpMQv8wxnQFLgKeP2Kz29ccBZwF/AvAWltlrT2Iy9dN3W9Ia2aMaQw0B3bjwjVb\na78A9v9i87HWOQl401pbaa3dAuRS13knJRgKvQuw44j7O73bXMsYEwecBnwPdLTW5nsf2gO47Tdk\nPwbMBDxHbHP7mnsAe4EXvYeanjfGtMDF67bW7gIeAbYD+UCxtfZjXLzmXzjWOn3ab8FQ6CHFGNMS\nSAP+bK0tOfIxW3dKkmtOSzLGTAQKrbVrj/Uct63ZqzEwBHjaWnsaUMYvDjW4bd3eY8aTqPvHrDPQ\nwhhz7ZHPcduaj8Wf6wyGQt8FdDviflfvNtcxxoRTV+avW2sXeTcXGGNivI/HAIVO5fOD0cAlxpit\n1B1KO9cY8xruXjPU7YXttNZ+772/kLqCd/O6xwFbrLV7rbXVwCJgFO5e85GOtU6f9lswFPpqIN4Y\n08MY04S6DxCWOpzJ54wxhrpjqhustX8/4qGlwDTv7WnAkobO5i/W2lnW2q7W2jjqvq+fWmuvxcVr\nBrDW7gF2GGP6ejeNBbJw97q3AyONMc29f9fHUvc5kZvXfKRjrXMpcJUxpqkxpgcQD/xw0u9irQ34\nP8CFwEZgMzDH6Tx+WuMZ1P1vWDrws/fPhUBb6j4V3wSsAKKdzuqn9Y8Blnlvu37NwGBgjff7/S7Q\nxu3rBu6YF8nZAAAAXElEQVQBsoFM4FWgqRvXDLxB3ecE1dT939j0/7ROYI6323KACafy3rpSVETE\nJYLhkIuIiNSDCl1ExCVU6CIiLqFCFxFxCRW6iIhLqNBFRFxChS4i4hIqdBERl/hvUXRKredRRKsA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaeba75ac>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(100)\n",
    "y = .5 * x + 4\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use this function to create our training set. We do this by adding noise (called delta in the code) to the function. The X values remain the same but the responses will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb428f5ac>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(100)\n",
    "delta = np.random.uniform(-10,10, size=(100,))\n",
    "y_hat = .5 * x + 4 + delta\n",
    "plt.scatter(x,y_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the response is definitely linear but the two plots do not have the same responses. We will use the x array and the y_hat array as our training set. We first need to find the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_mean = x.mean()\n",
    "y_mean = y_hat.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate $\\hat{\\beta}_{0}$ and $\\hat{\\beta}_{1}$ using the equations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta1_hat = np.sum((x-x_mean)*(y_hat-y_mean))/np.sum(np.power((x-x_mean),2))\n",
    "beta0_hat = y_mean - beta1_hat*x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0320882952776316"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta0_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48510614019606407"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta1_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficents $\\hat{\\beta}_{1}$ and $\\hat{\\beta}_{0}$ are clearly not exact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this again and randomize the X values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xad4e910c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.uniform(0,100, size=(100,))\n",
    "delta = np.random.uniform(-10,10, size=(100,))\n",
    "y_hat = .5 * x + 4 + delta\n",
    "plt.scatter(x,y_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_mean = x.mean()\n",
    "y_mean = y_hat.mean()\n",
    "beta1_hat = np.sum((x-x_mean)*(y_hat-y_mean))/np.sum(np.power((x-x_mean),2))\n",
    "beta0_hat = y_mean - beta1_hat*x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5944663404667843"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta0_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49717307152004003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta1_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scypy package in Python has a function that will calculate the coefficients for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "slope, intercept, r_value, p_value, std_error = stats.linregress(x,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49717307152004026"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5944663404667736"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both beta0_hat is exactly the same as the slope variable and beta1_hat is exactly the same as the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging $\\hat{\\beta}_{0}$ and $\\hat{\\beta}_{1}$ over many data sample sets\n",
    "Now what if we were to take a lot of data samples and average the slopes and intercepts from each of the data sample sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "size = 10\n",
    "slopes = np.empty(size)\n",
    "intercepts = np.empty(size)\n",
    "for i in range(size):\n",
    "    x = np.random.uniform(0,100, size=(100,))\n",
    "    delta = np.random.uniform(-10,10, size=(100,))\n",
    "    y_hat = .5 * x + 4 + delta\n",
    "    slope, intercept, r_value, p_value, std_error = stats.linregress(x,y_hat)\n",
    "    slopes[i] = slope\n",
    "    intercepts[i] = intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49957301101573715"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slopes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1094309744012154"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercepts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 100\n",
    "slopes = np.empty(size)\n",
    "intercepts = np.empty(size)\n",
    "for i in range(size):\n",
    "    x = np.random.uniform(0,100, size=(100,))\n",
    "    delta = np.random.uniform(-10,10, size=(100,))\n",
    "    y_hat = .5 * x + 4 + delta\n",
    "    slope, intercept, r_value, p_value, std_error = stats.linregress(x,y_hat)\n",
    "    slopes[i] = slope\n",
    "    intercepts[i] = intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50212405781817426"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slopes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9831891256113829"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercepts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 1000\n",
    "slopes = np.empty(size)\n",
    "intercepts = np.empty(size)\n",
    "for i in range(size):\n",
    "    x = np.random.uniform(0,100, size=(100,))\n",
    "    delta = np.random.uniform(-10,10, size=(100,))\n",
    "    y_hat = .5 * x + 4 + delta\n",
    "    slope, intercept, r_value, p_value, std_error = stats.linregress(x,y_hat)\n",
    "    slopes[i] = slope\n",
    "    intercepts[i] = intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49901398481122949"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slopes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0550590223558096"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercepts.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 10000\n",
    "slopes = np.empty(size)\n",
    "intercepts = np.empty(size)\n",
    "for i in range(size):\n",
    "    x = np.random.uniform(0,100, size=(100,))\n",
    "    delta = np.random.uniform(-10,10, size=(100,))\n",
    "    y_hat = .5 * x + 4 + delta\n",
    "    slope, intercept, r_value, p_value, std_error = stats.linregress(x,y_hat)\n",
    "    slopes[i] = slope\n",
    "    intercepts[i] = intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49998210625035533"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slopes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9931314705813472"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercepts.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more we average $\\hat{\\beta}_{0}$ and $\\hat{\\beta}_{1}$ from many data samples, the closer and closer the coefficients will approach the \"unknown\" function's coefficients $\\beta_{0}$ and $\\beta_{1}$. So what can we learn from this? What is being shown is an unbias in the estimate. There is no intent to intentionally overshoot or undershoot the individual slope or intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $\\hat{\\mu}$ is the mean (average) of the samples and $\\sigma$ is the standard deviation. Var($\\hat{\\mu}$) is the variance of the sample population. First, let's discuss the variance of the sample mean. More formally the sample variance is described by the following equation(http://mathworld.wolfram.com/Variance.html):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$Var(\\hat{\\mu}) = \\frac{1}{n-1}\\sum_{i=1}^n(y_{i}-\\bar{y})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the equation, what can we learn about the variance? In a nutshell, we are looking at the sample spread from the mean of the response or how spread out/by how much do the samples vary (On a side note, if you want to know why the differences are squared, see the footnote at http://www.mathsisfun.com/data/standard-deviation.html). Here is the link to a very good video on the sample variance: https://www.youtube.com/watch?v=sOb9b_AtwDg (Population and Sample Variance from MathTutorDVD.com). We know that if we take the average $\\hat{\\mu}$ over many data sets, $\\hat{\\mu}$ would move closer and closer to the actual population $\\mu$. Since each data set will produce its own $\\hat{\\mu}$, a question we could ask ourselves is by how far off an individual $\\hat{\\mu}$ will be from $\\mu$. The Standard Error (SE) will help in answering that question. Standard errors will also help us establish a confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Var(\\hat{\\mu}) = SE(\\hat{\\mu})^2 = \\frac{\\sigma^2}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Standard error: https://www.youtube.com/watch?v=BwYj69LAQOI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By inspection of the equation we can see that as the standard deviation goes up, so will the standard error. In contrast as the number of observations goes up the standard error will go down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend this logic to the coefficients of our function and determine their accuracy. For the standard errors of $\\hat{\\beta}_{0}$ and $\\hat{\\beta}_{1}$ we have the following equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$SE(\\hat{\\beta}_{0})^2 = \\sigma^2[\\frac{1}{n}+\\frac{\\bar{x}^2}{\\Sigma_{i=1}^n(x_{i}-\\bar{x})^2}], \\space SE(\\hat{\\beta}_{1})^2 = \\frac{{\\sigma}^2}{\\Sigma_{i=1}^n(x_{i}-\\bar{x})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for these equations to hold $\\epsilon$ for each observation must be uncorrelated. $\\sigma^2$ is unknown but can be estimated using the Residual Standard Error (RSE):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma^2\\approx\\ RSE\\ = \\ \\sqrt{\\frac{RSS}{(n-2)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard errors are also used to execute hypothesis tests such as the null hypothesis test on the coefficients of the unknown function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis: X has no effect on Y.\n",
    "\n",
    "Alternative hypothesis: X has some effect on Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the null hypothesis test we need to establish that $\\hat{\\beta_{1}}$ is far enough from zero that we can be confident that $\\hat{\\beta_{1}}$ is non-zero. The standard error can be helpful in determining if $\\hat{\\beta_{1}}$ is far enough from zero to be considered non-zero. This is because being sufficiently far from zero depends a lot on the accuracy of $\\hat{\\beta_{1}}$. The t-statistic is used to compare the standard error to $\\hat{\\beta_{1}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$t=\\frac{\\hat{\\beta_{1}}-\\beta_{1}}{SE({\\hat{\\beta_{1}})}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to make an set $\\beta_{1}$ to zero to test the null hypothesis, or in other words, we are testing to see X has no relationship with Y. So, setting $\\beta_{1}=0$ we have the following t-statistic:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$t=\\frac{\\hat{\\beta_{1}}-0}{SE({\\hat{\\beta_{1}})}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really what this equation tells us is how many standard deviations $\\beta_{1}$ is from 0. Now we will go through an example of calculating the t-statistic and plotting the result over many iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xabe0238c>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xabe54c0c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "size = 10000\n",
    "t = np.empty(size)\n",
    "p = np.empty(size)\n",
    "for i in range(size):\n",
    "    x = np.random.uniform(0,100, size=(10,))\n",
    "    delta = np.random.uniform(-10,10, size=(10,))\n",
    "    y_hat = .5 * x + 4 + delta\n",
    "    slope, intercept, r_value, p_value, std_error = stats.linregress(x,y_hat)\n",
    "    t[i] = slope / std_error\n",
    "    p[i] = p_value\n",
    "\n",
    "t = sorted(t)\n",
    "pdf = stats.norm.pdf(t, np.mean(t), np.std(t))\n",
    "plt.plot(t, pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the statistic follows a normal distribution. In this case the mean is about 8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the t-statistic has been calculated we can compute the p-value which is what we are really interested in. A very small p-value is an indication that we can reject the null hypothesis, meaning that there is a high probability of a relationship between the X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005510471820596004"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical cutoffs of the p-value are 5% or 1% in order to reject the null hypothesis. Clearly at there is a high probability that X is related to Y in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know there is a high degree of likelihood that we can reject the null hypothesis for our coefficient, we need to determine the effectiveness of our model. We can use the Residual Standard Error (RSE) and the $R^2$ statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The RSE measures the standard deviation of the error $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$RSE = \\sqrt{\\frac{RSS}{n-2}}=\\sqrt{\\frac{1}{n-2}\\Sigma_{i=1}^n(y_{i}-\\hat{y_{i}})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.618658202212803"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "n = 100\n",
    "\n",
    "x = np.random.uniform(0,100, size=(n,))\n",
    "delta = np.random.uniform(-10,10, size=(n,))\n",
    "y_hat = .5 * x + 4 + delta\n",
    "slope, intercept, r_value, p_value, std_error = stats.linregress(x,y_hat)\n",
    "\n",
    "math.sqrt(np.sum(np.square(y_hat-(slope*x+intercept))) / (n - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.454571854078573"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the RSS is in units of Y. The result above show us by what percentage the RSS is of the mean. The RSE shows how bad of a fit is our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other useful tool for determining the accuracy of our model the $R^2$ statistic which is not units of Y but rather is a proportion. $R^2$ lets us figure out what percentage of Y can be explained by X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R^2=\\frac{TSS-RSS}{TSS}=1-\\frac{RSS}{TSS}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the Total Sum of Squares (TSS) is defined as: $TSS=\\Sigma(y_{i}-\\bar{y})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717181991528345"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.pow(r_value,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run through some more examples and see how $R^2$ changes as the error changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9599504434123102"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "error = 5\n",
    "n = 100\n",
    "\n",
    "x = np.random.uniform(0,100, size=(n,))\n",
    "delta = np.random.uniform(-error,error, size=(n,))\n",
    "y_hat = .5 * x + 4 + delta\n",
    "slope, intercept, r_value, p_value, std_error = stats.linregress(x,y_hat)\n",
    "\n",
    "rse = math.sqrt(np.sum(np.square(y_hat-(slope*x+intercept))) / (n - 2))\n",
    "math.pow(r_value,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142063168172001"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "error = 15\n",
    "n = 100\n",
    "\n",
    "x = np.random.uniform(0,100, size=(n,))\n",
    "delta = np.random.uniform(-error,error, size=(n,))\n",
    "y_hat = .5 * x + 4 + delta\n",
    "slope, intercept, r_value, p_value, std_error = stats.linregress(x,y_hat)\n",
    "\n",
    "rse = math.sqrt(np.sum(np.square(y_hat-(slope*x+intercept))) / (n - 2))\n",
    "math.pow(r_value,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6349836732498763"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "error = 20\n",
    "n = 100\n",
    "\n",
    "x = np.random.uniform(0,100, size=(n,))\n",
    "delta = np.random.uniform(-error,error, size=(n,))\n",
    "y_hat = .5 * x + 4 + delta\n",
    "slope, intercept, r_value, p_value, std_error = stats.linregress(x,y_hat)\n",
    "\n",
    "rse = math.sqrt(np.sum(np.square(y_hat-(slope*x+intercept))) / (n - 2))\n",
    "math.pow(r_value,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous three examples, it is interesting to see how $R^2$ changes as the error increases and decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now we have only considered simple linear regression. Multiple linear regression also needs to be addressed. We will give an example of multiple linear regression using two packages in Python: statsmodel, and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.150e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 28 Aug 2017</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:33:40</td>     <th>  Log-Likelihood:    </th> <td> -31717.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 10000</td>      <th>  AIC:               </th> <td>6.344e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9997</td>      <th>  BIC:               </th> <td>6.346e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.9699</td> <td>    0.154</td> <td>   25.855</td> <td> 0.000</td> <td>    3.669</td> <td>    4.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>     <td>    0.5018</td> <td>    0.002</td> <td>  250.654</td> <td> 0.000</td> <td>    0.498</td> <td>    0.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>z</th>     <td>    2.9998</td> <td>    0.002</td> <td> 1496.761</td> <td> 0.000</td> <td>    2.996</td> <td>    3.004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>7834.924</td> <th>  Durbin-Watson:     </th> <td>   1.977</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 588.628</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.013</td>  <th>  Prob(JB):          </th> <td>1.52e-128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.812</td>  <th>  Cond. No.          </th> <td>    204.</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.996\n",
       "Model:                            OLS   Adj. R-squared:                  0.996\n",
       "Method:                 Least Squares   F-statistic:                 1.150e+06\n",
       "Date:                Mon, 28 Aug 2017   Prob (F-statistic):               0.00\n",
       "Time:                        15:33:40   Log-Likelihood:                -31717.\n",
       "No. Observations:               10000   AIC:                         6.344e+04\n",
       "Df Residuals:                    9997   BIC:                         6.346e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.9699      0.154     25.855      0.000       3.669       4.271\n",
       "x              0.5018      0.002    250.654      0.000       0.498       0.506\n",
       "z              2.9998      0.002   1496.761      0.000       2.996       3.004\n",
       "==============================================================================\n",
       "Omnibus:                     7834.924   Durbin-Watson:                   1.977\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              588.628\n",
       "Skew:                          -0.013   Prob(JB):                    1.52e-128\n",
       "Kurtosis:                       1.812   Cond. No.                         204.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "error = 10\n",
    "n = 10000\n",
    "\n",
    "x = np.random.uniform(0,100, size=(n,))\n",
    "z = np.random.uniform(0,100, size=(n,))\n",
    "delta = np.random.uniform(-error,error, size=(n,))\n",
    "y_hat = .5 * x + 4 + delta + 3 * z\n",
    "\n",
    "d = {'x': x, 'z': z,}\n",
    "X = pd.DataFrame(d)\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y_hat, X).fit()\n",
    "predictions = model.predict(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "error = 10\n",
    "n = 10000\n",
    "\n",
    "x = np.random.uniform(0,100, size=(n,))\n",
    "z = np.random.uniform(0,100, size=(n,))\n",
    "delta = np.random.uniform(-error,error, size=(n,))\n",
    "y_hat = .5 * x + 4 + delta + 3 * z\n",
    "\n",
    "d = {'x': x, 'z': z}\n",
    "X = pd.DataFrame(d, columns=['x','z'])\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X,y_hat)\n",
    "predictions = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99569861326365217"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R^2\n",
    "lm.score(X,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49993206,  3.00133552])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8881956809788676"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see both packages do a very good job in calculating the coefficients. We will be using sklearn in future examples, though statsmodels package is nice in that the F-statistic (which will be explained further down) in included in the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important question to answer is if all the predictors have an influence on the response. In simple linear regression we used the null hypothesis test. Similarily, we test the null hypothesis for all the predictors. This appears in the form of: $\\beta_{1} = \\beta_{2} = ... = \\beta_{p} = 0$. This is where the F-statistic is useful. The further from one, the less likely will the null hypothesis test be true. The size of n and p will determine exactly how far from one we need to be before rejecting the null hypothesis. Though the F-statistic shows that there is a relationship between the response and at least one of the predictors. A subset of the predictors can be used to calculate the F-statistic. To determine which predictors do not have a relationship with the response will not be discussed here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$F=\\frac{\\frac{TSS-RSS}{p}}{\\frac{RSS}{(n-p-1)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now we have only discussed continuous independent predictors, but what about categorical predictors? Turns out that dummy variables can be used to represent the categores. Suppose we have a coin toss category which contain heads and tails. In this example we set a dummy variable to be 1 if the toss is heads and 0 if the value is tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_{i} = \\begin{cases}\n",
    "\\text1\\hspace{10mm} if\\ the\\ ith\\ toss\\ is\\ heads\\\\\n",
    "\\text0\\hspace{10mm} if\\ the\\ ith\\ toss\\ is\\ tails\\\\\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are left with the equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y_{i} = \\beta_{0}+\\beta_{i}x_{i}+\\epsilon_{i} = \\begin{cases}\n",
    "\\beta_{0} + \\beta_{1} + \\epsilon_{i}\\hspace{10mm}\\text if\\ the\\ ith\\ toss\\ is\\ heads\\\\\n",
    "\\beta_{0} + \\epsilon_{i}\\hspace{21mm}\\text if\\ the\\ ith\\ toss\\ is\\ tails\\\\\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are more than two levels per category,then we will need (levels - 1) dummy variables. For example, if we have \n",
    "a category called colors with Red, Green, Blue, each of different sizes. We will need two variables to represent these three colors. The equation would assume the following form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_{i1}=\\begin{cases}\n",
    "1\\hspace{10mm}\\text if\\ the\\ ith\\ color\\ is\\ red\\\\\n",
    "0\\hspace{10mm}\\text if\\ the\\ ith\\ color\\ is\\ not\\ red\\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_{i2}=\\begin{cases}\n",
    "1\\hspace{10mm}\\text if\\ the\\ ith\\ color\\ is\\ green\\\\\n",
    "0\\hspace{10mm}\\text if\\ the\\ ith\\ color\\ is\\ not\\ green\\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y_{i} = \\beta_{0}+\\beta_{1}x_{i1}+\\beta_{2}x_{i2}+\\epsilon_{i} = \\begin{cases}\n",
    "\\beta_{0} + \\beta_{1} + \\epsilon_{i}\\hspace{10mm}\\text if\\ the\\ ith\\ color\\ is\\ red\\\\\n",
    "\\beta_{0} + \\beta_{2} + \\epsilon_{i}\\hspace{10mm}\\text if\\ the\\ ith\\ color\\ is\\ green\\\\\n",
    "\\beta_{0} + \\epsilon_{i}\\hspace{21mm}\\text if\\ the\\ ith\\ color\\ is\\ blue\\\\\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta_{0}$ is the size of blue, $\\beta_{1}$ is the difference between the size of red and blue, $\\beta_{2}$ is the difference between the size of green and blue. $\\beta_{0} is known as the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
